{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 01\n",
    "## Notebook 1\n",
    "\n",
    "Group's members:\n",
    "\n",
    "    Crnigoj Gabriele 134176\n",
    "    Ferraro Tommaso 132998\n",
    "    Stinat Kevin 134905\n",
    "    \n",
    "<font color='green'>Note</font>: in red we write some comment for each exercise. At the end of the Notebook 02 it can be found our conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering the top 100 Greatest Movies of All Time (Part 1)\n",
    "\n",
    "IMBDb is a website containing movies rating. In particular, a set of top 100 greatest movies of all time is available at the URL http://www.imdb.com/list/ls055592025/ . This data is contained in form of a HTML page.\\\n",
    "Our ultimate goal will be to automatically fetch the data from that page and to process it in order to cluster the films.\n",
    "\n",
    "## Step 1: Getting the data\n",
    "In this phase, the goal is to scrape the data from the web and making a local copy of the relevant movie synopses for the following phases. In order to do that we will use the `requests` library for interacting with the web service and the `beautifulsoup` library for parsing html web pages and navigating into their content.\n",
    "\n",
    "### Interacting with a web site\n",
    "The `requests` library allows to interact with a web site from your Python script. In particular, it allows to download the content of a web page or a web service, given its address (more precisely its URL).\\\n",
    "\\\n",
    "In its essence the `requests` use one `http` method to issue a request to the web server and obtaines a response. This is the basic of the web interaction. In the following example we are interacting with the home page of the University of Udine, getting its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://www.uniud.it')\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `r` object is the response returned from the web server that is managing the page we have requested. In particular it is relevant to look whether the request was successfully honoured by the web server or some error occured. To do so, the `r.status_code` attribute can be inspected. It is a code, whose value is 200 if everything went fine (actually it is < `400` but we can skip a more detailed explanation now) or it might a value greater than or equal to `400` if something went wrong (all of you probably have experienced the 404 error `“Page not Found”` )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "request = requests.get('http://www.imdb.com/list/ls055592025/') \n",
    "print(request.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> The value of the response is 200, so the interaction with the website went fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual content of the page is typically encoded in the `HTML` language. This can be inspected by looking at the `r.headers` field of the response, i.e.,\\\n",
    "\\\n",
    "`r.headers['content-type']`\\\n",
    "\\\n",
    "which returns `text/html` when dealing with a regular website. In this case the content is of this type, the actual page content is available as the `r.text` or the `r.content` fields of the response. In general, however the interaction through the `http` protocol is possible also with web services, which usually returns data in different formats. For example, the site `http://www.omdbapi.com` allows to get the movie information from the IMDb site (Internet Movie Database) site as a web service, however it will need to be registred to that website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/html;charset=UTF-8\n"
     ]
    }
   ],
   "source": [
    "print(request.headers['content-type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> in this case the content is of this type, the actual page content is available as the r.text\n",
    "or the r.content fields of the response.\\\n",
    "Once the content has been retrieved, if it is in form of an HTML page it could be manipulated through the beautifulsoup library. Through the page object, now it is possible to navigate and search the HTML content, retrieving a specific fragment of the page itself (more later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the content has been retrieved, if it is in form of an HTML page it could be manipulated through the `beautifulsoup` library. In particular the content can be parsed in this way:\\\n",
    "\\\n",
    "`\n",
    "import BeautifulSoup from bs4\n",
    " page = BeautifulSoup(res.content)\n",
    "`\n",
    "\\\n",
    "\\\n",
    "Through the `page` object, now it is possible to navigate and search the HTML content, retrieving a specific fragment of the page itself (more later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "page = BeautifulSoup(request.content)\n",
    "\n",
    "#page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font>\\\n",
    "r.content : show the page in HTML\\\n",
    "BeautifulSoup : Trasform that page into a webpage readible in HTML\\\n",
    "Print(page) : show me the entire content of the page. We don't print it because of the lenght of the print."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 1\n",
    "\n",
    "The list of the 100 greatest movie of all the time (you will find it in the file `greatest_movies.xlsx`. Given the data extract the synopsis of each movie and save it to a file whose name is the title of the movie. To get the synopsis, you may use the following function \"get_synopsis(id)\".\n",
    "```\n",
    "def get_synopsis(id):\n",
    "    res = requests.get('https://www.imdb.com/title/{movie_id}/plot\n",
    "    summary'.format(movie_id=id))\n",
    "    if res.status_code != 200:\n",
    "        return None\n",
    "    page = BeautifulSoup(res.content)\n",
    "    synopsis = page.select(\"#plot-synopsis-content\")\n",
    "    return synopsis[0].text.strip()\n",
    "```\n",
    "This function will interact with the `imdb` website getting the description page\n",
    "of each movie and extracting just the synopsis.\\\n",
    "\\\n",
    "**Note**: it would be better to save the movies files inside a directory instead of creating them in the current directory. For this purpose, you can refer to the `os` library that allows to interact with the operating system. In particular `os.mkdir(name)` will create a new directory whose name is name . In order to create the directory only if it does not exist previously, you can use the `os.path.exists(name)` method that checks if the directory (or a single file already exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> First of all, we read the data from the file '.xlsx' and create a DataFrame\\\n",
    "Then we clean and improve the readability of the DataFrame, deleting the 'Unnamed: 0' column that became from an error due to the reading of the '.xlsx' file\\\n",
    "At the end we show the resul of that operation, displaying the first five rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>tt0068646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>tt0111161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>tt0108052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raging Bull</td>\n",
       "      <td>tt0081398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>tt0034583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title         id\n",
       "index                                     \n",
       "0                 The Godfather  tt0068646\n",
       "1      The Shawshank Redemption  tt0111161\n",
       "2              Schindler's List  tt0108052\n",
       "3                   Raging Bull  tt0081398\n",
       "4                    Casablanca  tt0034583"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_movies = 'greatest_movies.xlsx'\n",
    "greatest_movies = pd.read_excel(file_movies)\n",
    "\n",
    "greatest_movies.index.name = 'index'\n",
    "greatest_movies = greatest_movies.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "greatest_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> We define \"get_synopsis(id)\" that return the synopsis in text form, and after that, we make an example of what this function return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synopsis(id): \n",
    "    res = requests.get('https://www.imdb.com/title/{movie_id}/plotsummary'.format(movie_id = id))\n",
    "    if res.status_code != 200: #check che non mi dia errore\n",
    "        return None\n",
    "    page = BeautifulSoup(res.content)\n",
    "    synopsis = page.select(\"#plot-synopsis-content\")\n",
    "    return synopsis[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shawshank Redemption\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In 1947, Andy Dufresne (Tim Robbins), a banker in Maine, is convicted of murdering his wife and her lover, a golf pro. Since the state of Maine has no death penalty, he is given two consecutive life sentences and sent to the notoriously harsh Shawshank Prison. Andy keeps claiming his innocence, but his cold and calculating demeanor leads everyone to believe he did it.Meanwhile, Ellis Boyd Redding (Morgan Freeman), known as Red is being interviewed for parole after having spent 20 years at Shawshank for murder. Despite his best efforts and behavior, Red\\'s parole is rejected which doesn\\'t phase him all that much. Red is then introduced as the local smuggler who can get inmates anything they want within reason. An alarm goes off alerting all prisoners of new arrivals. Red and his friends bet on whichever new fish will have a nervous break down during his first night in prison. Red places a huge bet on Andy.During the first night, an overweight newly arrived inmate, nicknamed \\'\\'fat ass\\', breaks down and cries hysterically allowing Heywood (William Sadler) to win the bet. However, the celebration is short lived when the chief guard, Byron Hadley (Clancy Brown), savagely beats up the fat man for not keeping quiet when he is asked to. Meanwhile, Andy remains steadfast and composed. The next morning, the inmates learn that \\'\\'fat ass\\'\\' died in the infirmary because the prison doctor had been out for the night. Andy inquires about the man\\'s name only to get put down by Heywood.About a month later, Andy approaches Red having heard of his talents for finding things. He asks Red to find him a rock hammer, an instrument he claims is necessary for his hobby of rock collecting and sculpting. Red asks a few questions about his intentions which Andy laughs off. Red agrees to place the order and also warns Andy about \\'\\'the sisters\\'\\', a group of prisoners who sexually assaults other prisoners, most importantly their leader, Boggs (Mark Rolston) who has a crush on Andy. Though other prisoners consider Andy \"a really cold fish,\" Red sees something in Andy, and likes him from the start. Red thinks Andy intends to use the hammer to engineer an escape in the future but when he finally sees the tool\\'s actual size, he understands why Andy laughed and laughs too, putting aside the thought that Andy could ever use it to dig his way out of prison.During the first two years of his incarceration, Andy spends most of his time working in the prison laundry or fighting off Boggs and the Sisters. Though he persistently resists and fights them every time, Andy is beaten and raped on a regular basis but keeps quiet about it.When a work detail for tarring the roof of one of the prison\\'s buildings is announced, Red pulls some strings to get Andy and a few of their mutual friends assigned to the job, giving everyone a break from the usual. During the job Andy overhears Hadley complaining about having to pay taxes for an upcoming inheritance. Drawing from his expertise as a banker, Andy lets Hadley know how he can shelter his money from the IRS by turning it into a one-time gift for his wife. He then offers to assist Hadley in filling out the paperwork in exchange for some cold beers for his fellow inmates while on the tarring job. Hadley first threatens to throw Andy off the roof, but eventually agrees and do provide the working inmates with cold beers before the job is finished. Red remarks that Andy may have engineered the privilege to build favor with the prison guards as much as with his fellow inmates, but he also thinks Andy did it simply to \"feel normal again.\"While watching a movie, Andy approaches Red with another unusual demand and asks for the actress Rita Hayworth. Red is surprised by the demand but agrees to place the order. As he exits the theater, Andy once more encounters the Sisters. Although he is able to talk his way out of being raped, he is brutally beaten within an inch of his life, putting him in the infirmary for a month. Boggs spends a week in solitary for the beating. When he comes out, he finds Hadley and his men waiting in his cell. They beat him so badly that he\\'s left unable to walk or eat solid food for the rest of his life and is transferred to a prison hospital upstate. The Sisters move on and never bother Andy again. When Andy gets out of the infirmary, he finds a bunch of rocks for him to sculpt and a giant poster of Rita Hayworth in his cell; presents from Red and his friends.Warden Samuel Norton (Bob Gunton) hears about how Andy helped Hadley and uses a surprise cell inspection to size Andy up. He finds Andy reading his copy of the Holy Bible and they talk about their favorite verses while the guards are turning the cell upside down looking for illegal possessions. Satisfied with their encounter, the warden leaves and almost forget to give Andy his Bible back. He then encourages Andy to keep reading the Bible saying that \\'\\'Salvation lays within\\'\\'.Andy is later advised that he will now work in the prison library with aging inmate Brooks Hatlen (James Whitmore). The reason for his transfer is made obvious when a prison guard shows up asking Andy for financial advising. Andy sets-up a makeshift desk and starts working, providing financial advising to most prison guards and helping them with their income tax returns. Andy also sees an opportunity to expand the prison library; he starts by asking the Maine state senate for funds. He writes letters every week. His financial support practice is so appreciated that even guards from other prisons, when they visit for inter-prison baseball matches, seek Andy\\'s financial expertise. Even the warden himself has Andy preparing his tax returns.Not long afterwards, Brooks snaps and threatens to kill Heywood in order to avoid being paroled. Andy is able to talk him down. When his friends discuss Brooks \\'behavior, Red sympathizes with Brooks having obviously become \"institutionalized,\" after spending 50 years at Shawshank. He has become essentially conditioned to be a prisoner for the rest of his life and is unable to adapt to the outside world. Red remarks: \"These walls are funny. First you hate \\'em, then you get used to \\'em. Enough time passes, you get so you depend on them.\" Brooks is paroled and goes to live in a halfway house. He is also given a job at a supermarket which he hates. Finding it impossible to adjust to life outside the prison, he eventually commits suicide, leaving the message \"Brooks was here\" carved on a wooden beam .After six years of writing letters, Andy receives $200 from the state for the library, along with a collection of old books and phonograph records. Though the state Senate thinks this will be enough to get Andy to halt his letter-writing campaign, he is undaunted and redoubles his efforts.When the donations of old books and records arrive at the warden\\'s office, Andy finds a copy of Mozart\\'s The Marriage of Figaro among the records. He locks the guard assigned to the warden\\'s office in the bathroom and plays the record over the prison\\'s PA system. The entire prison is soon captivated by the music. Red remarks that the voices of these women made everyone feel free, if only for a brief moment. Outside the office, Norton appears furious at the act of defiance, and orders Andy to turn off the record player. Andy responds by turning up the volume. The warden orders Hadley to break into the office and Andy is sent immediately to solitary confinement for two weeks. When he gets out, he tells his friends that the stretch was the \"easiest time\" he ever did in the hole because he spent it with Mozart\\'s Figaro stuck in his head for comfort. When the other prisoners tell him how unlikely that is, he talks about the power that hope can have in prison and that hope can sustain them. Red strongly disagrees with Andy, claiming that hope is a dangerous thing in a place like Shawshank and tells Andy he should get used to living without it. Andy implies that this is exactly what Brooks did and Red leaves the table angry.Not long after, Red has a new parole hearing and realizes he\\'s been in prison for 30 years now. He uses the exact same words he used ten years earlier only with no enthusiasm at all. His parole is rejected again. Andy gives him an harmonica to commemorate his 30 years which Red replies by offering Andy a giant poster of Marilyn Monroe to commemorate his 10 years.About 4 years after the Mozart incident, the state senate finally comes to the conclusion that they won\\'t get rid of Andy with just another check. So they allow him a budget of 500$ a year to build his library. Andy uses it wisely and makes deals with book clubs and charities to create the best prison library in the state and names it after Brooks. With the enlarged library and more materials, Andy begins to mentor inmates who want to receive their high school diplomas so they can get a decent job once they\\'re out.Meanwhile, Warden Norton profits from Andy\\'s knowledge and devises a scheme whereby he puts prison inmates to work on public projects which he wins by outbidding other contractors (prisoners are cheap labor). Occasionally, he allows other contractors to score projects as long as the bribe is good enough. Andy launders the money by setting up several accounts in several banks, along with several investments, using the fake identity of Randall Stephens, a man who only exist on papers, created by Andy himself through his knowledge of the system and mail ordered forms. Randall Stephens officially has a birth certificate, social security number and driving license. Should anyone ever investigate about the scheme; they will chase a man who only exists on paper. Andy shares the details with Red, noting that he had to \"go to prison to learn how to be a crook.\"In 1965, a young prisoner named Tommy (Gil Bellows) comes to Shawshank to serve time for breaking and entering. Tommy is easy going, charismatic, and popular among the other inmates. When Tommy explains that he\\'s been going in and out of prison ever since he was 13 years old, Andy suggests that Tommy should consider another line of work besides theft because he seems to be not so good at it. The suggestion really gets to Tommy and he asks Andy to help him work on earning his high school equivalency diploma. Though Tommy is a good student, he is still frustrated when he takes the exam itself, crumpling it up and tossing it in the trash. Andy retrieves it and sends it in anyway. Tommy asks Red about Andy\\'s case which Red explains. Upon hearing the story, Tommy is visibly upset. He then tells Andy and Red the story of a former cellmate from another prison who boasted about killing a man who was a pro golfer at the country club he worked at, along with his lover. The woman\\'s husband, a banker, had gone to prison for those murders.With this new information, Andy, full of hope, meets with the warden, expecting Norton to help him get a new trial with Tommy as a witness. The reaction from Norton is completely contrary to what Andy hoped for. When Andy says emphatically that he would never reveal the money laundering schemes he set up for Norton over the years, the warden becomes furious and orders him to solitary for a month. The inmates discuss the sentence mentioning it is the longest time in solitary that they\\'ve ever heard of. They also realize that Andy may truly be innocent after all and has spent almost 20 years in prison for a crime he didn\\'t commit.Tommy receives a letter from the board of education announcing that he has passed the exam and now owns a high school diploma. A guard pass the news to Andy in his solitary cell which makes him smile a little.Later on, Tommy is escorted outside at night to have a private meeting with the warden. The warden asks him if the story he told Andy is true and if he would be willing to testify on Andy\\'s behalf. Tommy enthusiastically agrees. The warden smiles at him before nodding to Hadley to shoot him dead.When the warden visits Andy in solitary, he tells him that Tommy tried to escape and that Hadley had no choice but to shoot him. Andy doesn\\'t buy that story and tells Norton that \\'\\'everything\\'\\' stops and that he\\'s not going to work for him anymore. The warden threatens Andy to shut down the library, burn all the books, and move Andy to a much different cell in a much different part of the prison with the most hardened criminals should he stop working for him. He then leaves and orders Andy to another month in solitary to think about things.When Andy finally comes out of solitary, he and Red have a conversation where Andy talks about his wife and how much he loved her and feels responsible for her death even though he didn\\'t pulled the trigger. He then talks about his projects should he ever get out of prison. He talks about Zihuatanejo, a beach town on the Pacific coast of Mexico where he\\'d like to live for the rest of his life and manage a hotel there. He then asks Red if he\\'d join him to which Red says no and that he believes he is too far gone like Brooks. He then criticizes Andy for allowing hope to mess with his mind like that and that it will only destroy him. Andy agrees and is about to leave when he asks Red if he knows the Buxton, Maine area. He then tells Red about a very specific hay field where there is a large oak tree at the end of a stone wall. He then asks Red to promise him that, should he ever get paroled, he will seek that oak tree and retrieve something that was hidden amongst the stones but refuses to say what it is. Red promises but is worried about his friend\\'s state of mind. His worries are heightened further when he learns that Andy has asked Haywood for a 6 foot rope. Red believes Andy may have finally reached his breaking point and is about to commit suicide. Meanwhile, Norton asks Andy to shine his shoes for him and put his suit in for dry-cleaning before retiring for the night. Andy returns to his cell and the guards turn the lights off for the night. Red remarks that it was the longest night of his life.The following morning, Andy has not answered the morning call and is not standing in front of his cell like every morning. The guard yells at Andy for putting him late and walks to his cell expecting to find a seriously sick or dead Andy. At the same time, Norton becomes alarmed when he finds Andy\\'s shoes in his shoe box instead of his own. The alarm then goes off announcing a missing inmate. Norton rushes to Andy\\'s cell and demands an explanation. Hadley brings in Red, but Red insists he knows nothing of Andy\\'s plans. Becoming increasingly hostile and paranoid, Norton starts throwing Andy\\'s sculpted rocks around the cell. When he throws one at Andy\\'s poster of Raquel Welch (in the spot previously occupied by Marilyn Monroe, and before that by Rita Hayworth), the rock punches through and into the wall. Norton tears the poster from the wall revealing a tunnel just wide enough for a man to crawl into.Many years ago, not long after receiving his rock hammer, Andy innocently tried to carve his name on his cell wall when a chunk of it came off. Andy, being a fan of Geology, realized that the material the wall was made off of could make it possible for him to dig a hole in case he ever needed to escape. Andy first ordered the giant poster of Rita Hayworth to hide the hole. He then spent years digging at night with his rock hammer and hiding the dirt from his job into his pockets which he would then empty in the courtyard during his morning walks. When Tommy was killed, Andy decided it was time to go.During the previous night\\'s thunderstorm, Andy wore Norton\\'s clothes underneath his own to his cell, catching a lucky break when no one notices Norton\\'s shiny black shoes on his feet, including Red. He packed many of his belongings, some papers and Norton\\'s clothes into a plastic bag which he tied to himself with the rope he\\'d asked for, and escaped through his hole. The tunnel he\\'d excavated led him to a space between two walls of the prison where he found a sewer main line. Using a rock, he hit the sewer line in time with the lightning strikes and eventually broke it open. After crawling through 500 yards of the raw sewage contained in the pipe, Andy emerged in a brook outside the walls. A search team later found his prison clothes, a bar of soap and a very worn out rock hammer.While the warden and Red are discovering Andy\\'s genius escape, Andy walks into the Maine National Bank in Portland, where he had put Norton\\'s money. Using his assumed identity as Randall Stephens, and with all the necessary documentation, he closes the account and walks out with a cashier\\'s check. Before he leaves, he asks them to drop a package in the mail. He continues his visitations to nearly a dozen other local banks, ending up with some $370,000. The package contains Warden Norton\\'s accounting books, which are delivered straight to the Portland Daily Bugle newspaper along with Andy\\'s written confessions and testimony.Not long after, the police storm Shawshank Prison. Hadley is arrested for murder; Red says he was taken away \"crying like a little girl.\" Warden Norton finally opens his safe, which he hadn\\'t touched since Andy escaped, and instead of his books, he finds the Bible he had given Andy with a note to the warden saying that he was right, \"salvation did lay within\". Norton then opens it to the book of Exodus and finds that the pages had all been cut out in the shape of Andy\\'s rock hammer. Norton walks back to his desk as the police pound on his door, takes out a small revolver and shoots himself in the head. Red remarks that he wondered if the warden thought, right before pulling the trigger, how \"Andy could ever have gotten the best of him.\"Shortly after, Red receives a postcard from Fort Hancock, Texas, with nothing written on it. Red takes it as a sign that Andy made it into Mexico to freedom. Red and his buddies kill time talking about Andy\\'s exploits (with a few embellishments), but Red falls into a sort of depression from missing his friend.At Red\\'s next parole hearing in 1967, he talks to the parole board about how \"rehabilitated\" is just a made-up word invented to justify their job. He then explains how much he regrets his actions of the past, not because he\\'s in jail but because he knows how wrong it was. He then closes by saying that he has to live with that for the rest of his life and ask the board to stop wasting his time and leave him alone. His parole is finally granted. He goes to live and work at the same places that Brooks did, even seeing Brooks \\'message carved into the wooden beam. He frequently walks by a pawn shop which has several guns in the window. At times he contemplates trying to get back into prison feeling that he has no life outside of prison where he has spent most of his adult life, but he remembers the promise he made to Andy. He then reveals that he was not looking at the guns but at the compasses behind the guns and he bought one.Red follows Andy\\'s instructions, hitchhiking to Buxton and finding the stone wall Andy described. Just as Andy said, there is a large black stone. Underneath is a small box containing a large sum of cash and instructions to come find him in Zihuatanejo although he doesn\\'t name the city just in case. He also says he needs somebody \"who can get things\" for a \"project\" of his. Red suddenly understands all the power of hope and feels exhilarated by the feelings inside of him.After carving a new message in the wooden beam which reads: \"Brooks was here, so was Red\", Red violates parole and leaves the halfway house, unconcerned since no one is likely to do an extensive manhunt for \"an old crook like [him].\" He takes a bus to Fort Hancock, where he crosses into Mexico. The two friends are finally reunited on a beach of the Pacific coast, just like Andy had been hoping for.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(greatest_movies['title'][1])\n",
    "get_synopsis(greatest_movies['id'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> We proceeded by creating the folder in which we want to save the text files and we check that the folder exists, and then we created each file with the title equal to the id of the film (not the title because were born problems with the film's titles that contained punctuation symbols) and at the end we save inside them each synopsis.\\\n",
    "We also use 'tqdm' function to analyze the progress status of the processing of the function\\\n",
    "\\\n",
    "**Note**: if there weren't any kind of error in the films' title, we would have used the function below, paying attention to delete the punctation:\n",
    "\n",
    "```\n",
    "for c,movie_id in tqdm(enumerate(greatest_movies['id'])):\\\n",
    "    sinossi=get_synopsis(movie_id)\\\n",
    "    with open(os.path.join(save_path,'{title}.txt'.format(title=greatest_movies['title'][c])),'w') as r:\\\n",
    "        r.write(sinossi)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('Best 100 film\\'s synopsis')\n",
    "save_path = 'Best 100 film\\'s synopsis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('Best 100 film\\'s synopsis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:39<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('Best 100 film\\'s synopsis/') == True:\n",
    "    for movie_id in tqdm(greatest_movies['id']): #movie_id = id of each film\n",
    "    \n",
    "        sinossi = get_synopsis(movie_id)\n",
    "        \n",
    "        with open(os.path.join(save_path,'{title}.txt'.format(title = movie_id)),'w') as r:\n",
    "            r.write(sinossi)\n",
    "else:\n",
    "    print('Directory not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data preparation\n",
    "\n",
    "Textual data needs a proper preparation for later analysis. In particular, the main activities involve the removal of the terms that are too frequent and do not convey significant meaning (such as articles, pronouns, or prepositions). This task is called **stopword removal**.\\\n",
    "\\\n",
    "Afterwards, a sort of normalization of the terms is needed. Indeed, terms appear in different inflected/derived forms, such as, for example, \"am\", \"are\", \"is\" all refer to the \"to be\" verb, \"car\", \"cars\", \"car's\", \"cars'\" all refer to \"car\".\\\n",
    "**Stemming** is the process of transforming the text so that the root of each stemmed version is used.\\\n",
    "\\\n",
    "Finally, once the text has been properly normalized it should undergo a **tokenization** process to transform the text flow in a list of terms, to be used either directly to represent the document or to be the source of other processing (e.g., -gram building).\\\n",
    "\\\n",
    "The goal of this phase is to get a proper representation of the documents (i.e., the movies) that can be used for the following clustering phase.\\\n",
    "\\\n",
    "To help in this phase we will make use of the `nltk` library (Natural Language Toolkit, https://www.nltk.org), a very comprehensive library for performing textual analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 2\n",
    "\n",
    "The  `nltk ` library provides a bunch of corpora, which are relevant textual sources for different purposes (e.g., 25,000 free books of the Gutenberg project, >10,000 documents of the Reuters news, ...).\\\n",
    "\\\n",
    "One particular corpus is the  `stopwords ` one, which contains the stopwords (in different languages), which is available in the  `nltk.corpus ` package. \\\n",
    "\\\n",
    "Load the whole  `stopwords ` corpus of the English language in a  `stopwords ` variable. For suggestion you can refer to https://www.nltk.org/book/ch02.html. \\\n",
    "\\\n",
    "**Note**: in order to use the corpora, you are required to download them, therefore you should issue the nltk.download(corpus_name) command for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 3\n",
    "\n",
    "The  `nltk.sent_tokenize(text) ` and the  `nltk.word_tokenize(sentence) ` are two notable functions for tokenizing a text to sentences and a sentence to word, respectively. It would be advisable also to normalize the tokens by transforming them to lowercase.\\\n",
    "\\\n",
    "A stemmer, instead, is a function that will transform each word to its root. A very popular one is the so-called *Snowball stemmer*, which is available from the package `nltk.stem.snowball` as `SnowballStemmer`. The `SnowballStemmer` constructor takes a string as its argument, which specifies the stemming language ( `\"english\"`in our case). \n",
    "\n",
    "Write a function `tokenize_and_stem(text)` that, given the text of the synopsis tokenizes its content, stems it, removes the stopwords and everything that is not a word (i.e., everything whose name does not start with a letter, can you write a regular expression for that?). \n",
    "\n",
    "**Note**: maybe you should download the `'punkt'` component for tokenizing sentences as `nltk.download('punkt')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english') \n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(synopsis):\n",
    "    \n",
    "    lists_tokenized = []\n",
    "    \n",
    "    synopsis = synopsis.lower() #Don't want capital letters\n",
    "    \n",
    "    sent_tokens = nltk.sent_tokenize(synopsis) #tokenizes the synopsis into sentences in a list called sent_tokenized\n",
    "    \n",
    "    for sentence in sent_tokens:\n",
    "        list_tokenized = nltk.word_tokenize(sentence) #tokenizes the words in a list called list_tokenized\n",
    "        lists_tokenized.extend(list_tokenized)\n",
    "        \n",
    "    list_stemmed = list(stemmer.stem(i) for i in lists_tokenized) #list with every token stemmed (the root of the word)\n",
    "    \n",
    "    only_words = list(filter(lambda x: x.isalpha(), list_stemmed)) #it mantainces only words and nothing else\n",
    "    \n",
    "    without_stopwords = list(filter(lambda x: x not in stopwords, only_words)) \n",
    "    #if lambda is true, keep the word in the liste, otherwise remove it\n",
    "    \n",
    "    return without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> after the importation of the above libraries, we wrote the function above which tokenize and do the stemming of a text . Now we can apply it to every file that we have saved before into a '.txt file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 4\n",
    "\n",
    "Load all the synopses from the directory into a list of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> After we see that during the exercise 5 we need the names (or the ids, but for a better readable form, we prefer the name of each film) we keep track of names and ids while the function is reading in order the '.txt' file. Then we can assign to the columns of the Dataframe the names of the correspounding film.\n",
    "For this porpouse we wrote the function \"convert\" and thet we print the result of the application of that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(dataframe, movie_id):\n",
    "    \n",
    "    return greatest_movies.loc[greatest_movies['id'] == movie_id]['title'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = []\n",
    "list_movie_id = []\n",
    "list_movie_title = []\n",
    "\n",
    "for movie_id in tqdm(greatest_movies['id']): #movie_id = id of each film\n",
    "    \n",
    "    with open(os.path.join('Best 100 film\\'s synopsis/','{title}.txt'.format(title = movie_id)),'r') as file:  \n",
    "        clean_token_list = tokenize_and_stem(file.read())\n",
    "        string_list.append(' '.join(clean_token_list))\n",
    "        \n",
    "        list_movie_id.append(movie_id)\n",
    "        list_movie_title.append(convert(greatest_movies, movie_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list_movie_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_movie_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> In the next step, we read the '.txt' files which contain the synopsis of each film. Then we save every synosy without the stopwords into a list of strings, to be ready for the next step: the start of the clustering. In the we show the result of the previous function.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 5\n",
    "\n",
    "Now we have to define any document (i.e., a movie synopsis) as a vector of features. In particular, we want to use the *tf.idf* to characterize each term (Term-Frequency Inverse document frequency), so that we will obtain a *tf.idf matrix*.\n",
    "\n",
    "In order to do that, we can make use of the `sklearn` library (Sci-Kit learn), a general purpose machine learning library. In particular, the tf.idf is available in the package `sklearn.feature_extraction.text` as the class `TfidfVectorizer`.\n",
    "\n",
    "In general, the `sklearn` classes have two peculiar methods `fit()` and `transform()` which let the data be learned and the model applied, respectively. In our case, the two operations can be combined in one, using the `fit_transform()` method.\n",
    "\n",
    "When a `TfidfVectorizer` is created a couple of parameters have to be provided:\n",
    "- `max_df` : the maximum frequency within the documents a given term can have to be used in the tf-idf matrix; a reasonable     value is (or 0.8 ). If the term appears everywhere it probably carries little meaning.\n",
    "- `min_df` : the minimum value for document frequencies; using values that appear too seldomly also carries little meaning, a reasonable value is (or 0.2).\n",
    "- `max_features` : the maximum terms (i.e., features) to be considered.\n",
    "- `ngram_range` : whether to look at single words or sequences of more than one token.\n",
    "- `tokenizer` : a function that will perform tokenization.\n",
    "\n",
    "Once the vectorizer is in place, the terms employed are possibly available through the `get_feature_names(`) method.\n",
    "\n",
    "The matrix returned from the vectorizer is a *document x terms* whose values are the *tf_df* metric computed for each pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> First we import the TfidfVectorizer class.\n",
    "- The **sklearn.feature_extraction** module deals with feature extraction from raw data.\n",
    "- The **sklearn.feature_extraction.text** submodule gathers utilities to build feature vectors from text documents.\n",
    "- The class **sklearn.feature_extraction.text.TfidfVectorizer** convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "- The input is expected to be the **sequence strings or bytes items** that are expected to be analyzed directly.\n",
    "\n",
    "Then we create a object which is associated with the class TfidfVectorizer.\n",
    "- min_df : the minimum value for document frequencies\n",
    "- max_features : the maximum terms (i.e., features) to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_1 = TfidfVectorizer(max_df = 0.8, min_df = 0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> Knowing about the short theory which we report below:\n",
    "- **fit_trasform()**: is a method of the TfidfVectorizer class. It is a quicker way to execute subsequently the functions fit() and then trasform().\n",
    "- **fit()**: fit the vectorizer to the training data and save the vectorizer to a variable.\n",
    "- **trasform()**: use the variable output from fit() to transformer validation/test data into a matrix (Returns: scipy.sparse.csr.csr_matrix).\n",
    "\n",
    "We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors.\n",
    "Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "\n",
    "**Note:** We not call for the next feature because we use their default value:\n",
    "- tokenizer : callable or None (default=None)\n",
    "- ngram_range : tuple (min_n, max_n) (default=(1, 1))\n",
    "- max_features : int or None (default=None)\n",
    "\n",
    "Now we can procede to the next steps, often controlling the correct result of each operation (for example we chack the shape of the matrix and the DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_vectorizer_vectors is the link to the matrix before we create the DataFrame \n",
    "\n",
    "tfidf_vectorizer_vectors_1 = tfidf_vectorizer_1.fit_transform(string_list)\n",
    "tfidf_vectorizer_vectors_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it saves the correct matrix with 100 columns (documents) and 475 rows (words). Notice that the vectors are vertical.\n",
    "#We can also see the dimension of the sparse matrix from the cell above\n",
    "\n",
    "tfidf_vectorizer_vectors_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfmatrix_1 = pd.DataFrame(tfidf_vectorizer_vectors_1.T.todense(), index = tfidf_vectorizer_1.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> We want to transform the matrix into a Pandas DataFrame with horizontal vectors instead of the vertical ones in the tfidf_vectorizer_vectors. It can be considered as sparse matrix as each vector contains few terms that will have a non-zero value and it is their **idf** value.\n",
    "\n",
    "- **.todense()** return a dense representation of this matrix. **tfidf_vectorizer_vectors is a sparse matrix**. It means that  almost all entries are zeros and it wastes a lot of memory. Ideed, If i call tfidf_vectorizer_vectors i'll obtain a link to the matrix which is saved in memory.\n",
    "- **.get_feature_names().** In the original matrix every column and row is represented by a number. The function is an array mapping from feature integer (columns and rows) indices to feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfmatrix_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_idfmatrix_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> As we have said before, we associate each column at its movie' id or name. We propose an example of both association, but we use the second one bucause of the better readibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf_idfmatrix_1.columns = list_movie_id\n",
    "tf_idfmatrix_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_idfmatrix_1.columns = list_movie_title\n",
    "tf_idfmatrix_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> To check our results we used an other method in which we use the **tokenize_and_stem** function into the **TfidfVectorizer**, passing a list of string in which there are all the synopsis readed into the '.txt' files. As we can see below we had used the **.toarray()** function to obtain a condence matrix. But for a more readability of the data, we think that it's better to use a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_2 = TfidfVectorizer(max_df=0.8, min_df=0.2, analyzer='word', tokenizer = tokenize_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_synopsis = []\n",
    "\n",
    "for movie_id in tqdm(greatest_movies['id']): #movie_id = id of each film\n",
    "    \n",
    "    with open(os.path.join('Best 100 film\\'s synopsis/','{title}.txt'.format(title = movie_id)),'r') as file:  \n",
    "        list_synopsis.append(file.read())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_vectors_2 = tfidf_vectorizer_2.fit_transform(list_synopsis)\n",
    "tfidf_vectorizer_vectors_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> The parameter **max_feature** select the first n-elements order by decrescent frequency. But we think that we had already too few words to manage our data so we preferred not to use this parameter. However we made an example of the **max_feature** usage.\n",
    "\n",
    "Notice that we arrive at the same result (same number of rows (or words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_3 = TfidfVectorizer(max_features = 350, max_df=0.8, min_df=0.2, analyzer='word', tokenizer = tokenize_and_stem)\n",
    "\n",
    "tfidf_vectorizer_vectors_3 = tfidf_vectorizer_3.fit_transform(list_synopsis)\n",
    "tfidf_vectorizer_vectors_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_vectors_3.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE 6\n",
    "\n",
    "We want to save the results of this preparation phase, which is embedded in the `tf_idfmatrix` object. To do that, we can use the `joblib` library (available as `sklearn.externals.joblib` , which allows to save a Python object to a (binary) file.\n",
    "\\\n",
    "\\\n",
    "The function `joblib.dump(object, filename)` writes the content to a file, whereas `pickle.load(filename)` reads from a file and returns the loaded object.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "import os\n",
    "os.mkdir('tf_idfmatrix')\n",
    "savedir = 'tf_idfmatrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(savedir, 'tf_idfmatrix_file')\n",
    "\n",
    "with open(filename,'wb') as r:\n",
    "    joblib.dump(tf_idfmatrix_1, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename,'rb') as r:\n",
    "    example = pickle.load(r)\n",
    "    \n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> In order to save the matrix we have to use Joblib library to save it into a directory called 'tf_idmatrix' and we create a file called in the same way to save our matrix.\n",
    "\n",
    "We use \"wb\" because it is a binary file. If we open the file, we can read it bacause it has a different way of reading than a normal file. For this reason, we load it with joblib.\n",
    "\n",
    "We open the sam file with pickle, to make an example of how to use that function. \n",
    "\n",
    "Then we can open a new Notebook and test if the dump of the binary file went fine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Comment:**</font> we notice that using pickle to load the data we receive a nunpy.ndarry, so this function not suit our work because we want to read the entire matrix that we dumped into the previous file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
